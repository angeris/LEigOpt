{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 10\n",
    "num_blocks = 100\n",
    "n = num_blocks*(b-1) + 1\n",
    "\n",
    "A = spzeros(n, n)\n",
    "\n",
    "for i = 1:num_blocks\n",
    "    top_left = (i-1)*(b-1) + 1\n",
    "    A[top_left:top_left+b-1, top_left:top_left+b-1] .= randn(b, b)\n",
    "end\n",
    "\n",
    "A = (A + A')/2;\n",
    "\n",
    "B = speye(n, n);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.009239 seconds (800 allocations: 212.766 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([-5.59754], [-8.31145e-19; 2.61561e-17; … ; 2.73608e-17; -2.81534e-18], 1, 9, 100, [-0.102409, 0.14521, 0.195165, 0.125402, 0.031822, -0.00651783, 0.279918, -0.0213263, -0.197338, -0.434905  …  0.000944501, -0.0327124, -0.0516399, 0.0537226, -0.0286441, 0.111385, 0.0989107, -0.0696658, 0.0281797, 0.0511693])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time eigs(A, nev=1, which=:SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curr t : -899.1288056022731\n",
      "Curr t : -451.2202204483291\n",
      "Curr t : -225.49410257896068\n",
      "Curr t : -112.96890241374686\n",
      "Curr t : -56.142890024639584\n",
      "Curr t : -28.392589892218503\n",
      "Curr t : -14.545908912667237\n",
      "Curr t : -7.926743561411388\n",
      "Curr t : -5.645263886603386\n",
      "Curr t : -5.602060265564332\n",
      "Curr t : -5.59892936755401\n",
      "  1.775434 seconds (1.28 M allocations: 4.349 GiB, 8.84% gc time)\n"
     ]
    }
   ],
   "source": [
    "# grad(chol_L, B) = -1 - trace(chol_L \\ B)\n",
    "@time begin\n",
    "\n",
    "function grad(chol_L::SparseArrays.CHOLMOD.Factor{Float64}, B::SparseMatrixCSC{Float64, Int64}, nu::Float64)\n",
    "    tr = 0\n",
    "    e_i = zeros(size(B, 2))\n",
    "    e_i[1] = 1\n",
    "    for i = 1:size(B, 2)\n",
    "        if i > 1\n",
    "            e_i[i-1] = 0\n",
    "            e_i[i] = 1\n",
    "        end\n",
    "        tr += (chol_L \\ e_i)[i]\n",
    "    end\n",
    "    return -1 + nu*tr\n",
    "end\n",
    "    \n",
    "eval_f(chol_L::SparseArrays.CHOLMOD.Factor, t::Float64, nu::Float64) = -t - nu*logdet(chol_L)\n",
    "\n",
    "curr_t = -100.\n",
    "step_size = 1\n",
    "nu = 1.\n",
    "\n",
    "L = A - curr_t*B\n",
    "init_chol_L = cholfact(L)\n",
    "chol_L = copy(init_chol_L)\n",
    "\n",
    "converged = false\n",
    "    \n",
    "prev_val = Inf\n",
    "    \n",
    "for i = 1:100\n",
    "    curr_grad = grad(chol_L, B, nu)\n",
    "    is_pos_def = false\n",
    "    while !is_pos_def\n",
    "        tent_t = curr_t - step_size*curr_grad\n",
    "        L .= A - tent_t*B\n",
    "\n",
    "        try\n",
    "            cholfact!(chol_L, L)\n",
    "            \n",
    "            curr_eval = eval_f(chol_L, tent_t, nu)\n",
    "            \n",
    "            if curr_eval > prev_val\n",
    "                step_size *= .5\n",
    "                continue\n",
    "            end\n",
    "            \n",
    "            prev_val = curr_eval\n",
    "            is_pos_def = true\n",
    "                \n",
    "            if abs(curr_grad)^2 < 1e-4\n",
    "                println(\"Curr t : $tent_t\")\n",
    "                if nu < 1e-4\n",
    "                    converged = true\n",
    "                    break\n",
    "                end\n",
    "                \n",
    "                nu *= .5\n",
    "                prev_val = Inf\n",
    "                break\n",
    "            end\n",
    "                \n",
    "            curr_t = tent_t\n",
    "            step_size *= 1.2\n",
    "            break\n",
    "\n",
    "        catch y\n",
    "            if isa(y, Base.LinAlg.PosDefException)\n",
    "                chol_L = copy(init_chol_L)\n",
    "                step_size *= .5\n",
    "            else\n",
    "                error(\"wtf?\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if converged\n",
    "        break\n",
    "    end\n",
    "end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-6.17813], [-8.86227e-19; 1.70165e-18; … ; -7.09836e-17; 1.31684e-18], 1, 9, 100, [-0.00832226, -0.00582737, -0.0372743, 0.0239053, 0.0278231, 0.00543517, 0.0221169, -0.00404483, -0.0160135, -0.00235164  …  0.047227, -0.0434156, -0.00583877, 0.0929452, -0.054085, 0.0507873, -0.0536809, -0.0842467, -0.109428, 0.07352])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigs(A,nev=1,which=:SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2940308"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnz(chol_L\\B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished optimizing iteration at nu : 1 with t 1.0484698606752908e-9\n",
      "Finished optimizing iteration at nu : 0.1 with t -0.669741490289786\n",
      "Finished optimizing iteration at nu : 0.010000000000000002 with t -0.9439482969657267\n",
      "Finished optimizing iteration at nu : 0.0010000000000000002 with t -0.9920922447141156\n",
      "Finished optimizing iteration at nu : 0.00010000000000000003 with t -0.9989789659628019\n",
      "Finished optimizing iteration at nu : 1.0000000000000004e-5 with t -0.9998748707422735\n"
     ]
    }
   ],
   "source": [
    "func(x, t, nu) = -t - nu*log(x - t)\n",
    "grad(x, t, nu) = -1 + nu/(x - t)\n",
    "\n",
    "curr_t = -100\n",
    "step_size = 1\n",
    "\n",
    "x_set = 1\n",
    "nu = 1\n",
    "epsilon = 1e-6\n",
    "prev_val = Inf\n",
    "\n",
    "for i=1:100\n",
    "    curr_grad = grad(x_set, curr_t, nu)\n",
    "    tent_t = curr_t - step_size*curr_grad\n",
    "    \n",
    "    if tent_t > x_set\n",
    "        step_size *= .5\n",
    "        continue\n",
    "    end\n",
    "    \n",
    "    tent_val = func(x_set, tent_t, nu)\n",
    "    \n",
    "    if tent_val > prev_val\n",
    "        step_size *= .5\n",
    "        continue\n",
    "    end\n",
    "    \n",
    "    prev_val = tent_val\n",
    "    \n",
    "    if abs(curr_grad)^2 < epsilon\n",
    "        println(\"Finished optimizing iteration at nu : $nu with t $tent_val\")\n",
    "        if nu < 1e-4\n",
    "            break\n",
    "        end\n",
    "        prev_val = Inf\n",
    "        nu *= .1\n",
    "    end\n",
    "    \n",
    "    curr_t = tent_t\n",
    "    \n",
    "    step_size *= 1.2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating METADATA...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of DataDeps...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of VersionParsing...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of ZMQ...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of HTTP...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpdating cache of Conda...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mComputing changes...\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUpgrading Compat: v0.67.0 => v0.68.0\n",
      "\u001b[39m\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mThe following packages have been updated but were already imported:\n",
      "- Compat\n",
      "Restart Julia to use the updated versions.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Pkg.update(\"Convex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.1",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
