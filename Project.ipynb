{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import itertools\n",
    "from scipy.sparse import bsr_matrix, csc_matrix, diags, eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVXPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = cvx.Variable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = cvx.Minimize(-t)\n",
    "constraints = [A - t * np.eye(n) >> 0]\n",
    "problem = cvx.Problem(objective, constraints)\n",
    "optimal_value = problem.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010011194220271543"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0014676378983795586"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_vectorized_matrix(A_matrices):\n",
    "    V_Z = form_vectorized_Z()\n",
    "    V_A = form_vectorized_A(A_matrices)\n",
    "    # Concat V_A to V_Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_vectorized_Z():\n",
    "    for i in range(num_blocks):\n",
    "        for l in range(b ** 2):\n",
    "            j = l // b\n",
    "            k = l % b\n",
    "            row_index = (i * (b - 1) + j) * n + (i) * (b - 1) + k\n",
    "            column_index = l + i  * b ** 2\n",
    "            print('Inserting 1 at ({0}, {1})'.format(row_index, column_index))\n",
    "            V[row_index, column_index] = 1\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_vectorized_A(A_matrices):\n",
    "    # Parameter: A_matrices is a list of A_1, A_2, ..., A_k.\n",
    "    #   A_matrices does NOT include A_0\n",
    "    V = np.zeros(shape=(n ** 2, len(A_matrices)))\n",
    "    for index in range(len(A_matrices)):\n",
    "        V[:, index] = A_matrices[index].flatten()\n",
    "    return V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_laplacian(n):\n",
    "    A_0_sparse = diags(diagonals=[-1.0, 2.0, -1.0], offsets = [-1, 0, 1], shape=(n, n))\n",
    "    return A_0_sparse.tocsc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_alternating_projections():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_strong_duality(A_0_sparse, A_0_nz, \n",
    "                              A_sparse_list, A_nz_list, \n",
    "                              c, \n",
    "                              x_primal_var, z_primal_var_list, \n",
    "                              lambda_dual_var,\n",
    "                              sigma_dual_var_list,\n",
    "                              pinv_C_cache):\n",
    "    # Project y = (x, lambda) onto c'x + d'eta - tr(Lambda * A_0) = 0\n",
    "    # Equivalently, projecting y onto Cy = d, where C = [c', -vec(A_0.nz)], d = 0\n",
    "    C = np.hstack((c, -A_0_sparse_vectorized))\n",
    "    d = np.zeros(C.shape[0])\n",
    "    y = np.vstack((x_primal_var[:,np.newaxis], lambda_dual_var[A_0_nz].T))\n",
    "    \n",
    "    if not 'projection_strong_duality' in pinv_C_cache:\n",
    "        pinv_C_cache['projection_strong_duality'] = scipy.linalg.pinv(C)\n",
    "    pinv_C = pinv_C_cache['projection_strong_duality']\n",
    "    \n",
    "    y_prime = pinv_C.dot(d)[:, np.newaxis] + (scipy.sparse.eye(pinv_C.shape[0]) - pinv_C.dot(C)).dot(y)\n",
    "    x_primal_var[:] = y_prime[0:len(x_primal_var)]\n",
    "    \n",
    "    lambda_dual_var[A_0_nz] = y_prime[len(x_primal_var):].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_dual_feasibility_equality_1(A_0_sparse, A_0_nz, \n",
    "                                          A_sparse_list, A_nz_list, \n",
    "                                          c, \n",
    "                                          x_primal_var, z_primal_var_list, \n",
    "                                          lambda_dual_var,\n",
    "                                          sigma_dual_var_list,\n",
    "                                          pinv_C_cache):\n",
    "    # For each i, project c, lambda such that c[i] + tr(Lambda * A_i) = 0\n",
    "    # Equivalently, project onto Cy = d, where C = [vec(A_i.nz)'] and y = Lambda[A_i.nz], d = -c[i]\n",
    "    for i in range(len(A_sparse_list)):\n",
    "        C = A_sparse_vectorized_list[i]\n",
    "        d = np.array([-c[i]])\n",
    "        y = lambda_dual_var[A_nz_list[i]]\n",
    "        \n",
    "        if not ('projection_dual_feasibility_equality_1', i) in pinv_C_cache:\n",
    "            pinv_C_cache[('projection_dual_feasibility_equality_1', i)] = scipy.linalg.pinv(C[np.newaxis, :])\n",
    "        pinv_C = pinv_C_cache[('projection_dual_feasibility_equality_1', i)]\n",
    "        \n",
    "        y_prime = pinv_C.dot(d) + (scipy.sparse.eye(pinv_C.shape[0]) - pinv_C.dot(C[np.newaxis,:])).dot(y.T)\n",
    "        lambda_dual_var[A_nz_list[i]] = y_prime.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_dual_feasibility_equality_2(A_0_sparse, A_0_nz, \n",
    "                                          A_sparse_list, A_nz_list, \n",
    "                                          c, \n",
    "                                          x_primal_var, z_primal_var_list, \n",
    "                                          lambda_dual_var,\n",
    "                                          sigma_dual_var_list,\n",
    "                                          pinv_C_cache):\n",
    "    for i in range(num_blocks):\n",
    "        C = np.hstack((np.eye(b**2), np.eye(b**2)))\n",
    "        d = np.zeros(b**2)\n",
    "        diag_idx = (b-1)*i\n",
    "        y = np.vstack((sigma_dual_var_list[i].flatten()[:,np.newaxis],\n",
    "                       lambda_dual_var[diag_idx:diag_idx+b, diag_idx:diag_idx+b].todense().flatten().T))\n",
    "        \n",
    "        if not ('projection_dual_feasibility_equality_2', i) in pinv_C_cache:\n",
    "            pinv_C_cache[('projection_dual_feasibility_equality_2', i)] = scipy.linalg.pinv(C)\n",
    "        pinv_C = pinv_C_cache[('projection_dual_feasibility_equality_2', i)]\n",
    "        \n",
    "        y_prime = pinv_C.dot(d)[:, np.newaxis] + (scipy.sparse.eye(pinv_C.shape[0]) - pinv_C.dot(C)).dot(y)\n",
    "        sigma_dual_var_list[i][:,:] = y_prime[:b**2].reshape(b,b)\n",
    "        lambda_dual_var[diag_idx:diag_idx+b, diag_idx:diag_idx+b] = y_prime[b**2:].reshape(b,b).T\n",
    "        \n",
    "        check = sigma_dual_var_list[i] + lambda_dual_var[diag_idx:diag_idx + b, diag_idx:diag_idx + b]\n",
    "        if not np.allclose(check, 0):\n",
    "            raise Exception('Dual feasibility equality 2 projection is inconsistent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_psd_cone(dense_A):\n",
    "    W, V = scipy.linalg.eigh(dense_A)\n",
    "    \n",
    "    dense_A[:,:] = V @ np.diag(np.maximum(0, W)) @ V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_primal_feasibility_equality(A_0_sparse, A_0_nz, \n",
    "                                          A_sparse_list, A_nz_list, \n",
    "                                          c, \n",
    "                                          x_primal_var, z_primal_var_list, \n",
    "                                          lambda_dual_var,\n",
    "                                          sigma_dual_var_list,\n",
    "                                          pinv_C_cache):\n",
    "\n",
    "    cols_z = scipy.sparse.csr_matrix((len(vector_to_matrix), b**2 * num_blocks))\n",
    "    rows_to_Z_idx = []\n",
    "\n",
    "    # First map the Z_i matrices\n",
    "    for curr_block_idx in range(num_blocks):\n",
    "        for i, j in itertools.product(range(b), range(b)):\n",
    "            ni, nj = curr_block_idx*(b-1) + i, curr_block_idx*(b-1) + j\n",
    "            # Generate the basis vectors\n",
    "            cols_z[matrix_to_vector[(ni, nj)], curr_block_idx*(b**2) + i*b + j] = 1\n",
    "\n",
    "    cols_A = scipy.sparse.csr_matrix((len(vector_to_matrix), len(A_sparse_list)))\n",
    "    for i in range(len(A_sparse_list)):\n",
    "        cols_A[:, i] = A_sparse_list[i][sparsity_pattern_rows, sparsity_pattern_cols][:,np.newaxis]\n",
    "\n",
    "    z_vector = np.zeros(b**2 * num_blocks)\n",
    "    for block_idx in range(num_blocks):\n",
    "        for i, j in itertools.product(range(b), range(b)):\n",
    "            z_vector[block_idx * (b ** 2) + (i * b) + j ] = (z_primal_var_list[block_idx])[i, j]\n",
    "\n",
    "    y = np.r_[z_vector, x_primal_var]\n",
    "    d = -A_0_sparse[sparsity_pattern_rows, sparsity_pattern_cols].T\n",
    "    C = scipy.sparse.hstack((-cols_z, cols_A)).todense()\n",
    "    \n",
    "    if not 'projection_primal_feasibility_equality' in pinv_C_cache:\n",
    "        pinv_C_cache['projection_primal_feasibility_equality'] = scipy.linalg.pinv(C)\n",
    "    pinv_C = pinv_C_cache['projection_primal_feasibility_equality']\n",
    "    \n",
    "    y_prime = pinv_C.dot(d) + (scipy.sparse.eye(pinv_C.shape[0]) - pinv_C.dot(C)).dot(y[:,np.newaxis])\n",
    "\n",
    "    for block_idx in range(num_blocks):\n",
    "        for i, j in itertools.product(range(b), range(b)):\n",
    "            z_primal_var_list[block_idx][i, j] = y_prime[block_idx * (b ** 2) + (i * b) + j ]\n",
    "\n",
    "    x_primal_var[:] = y_prime[-len(x_primal_var):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alternating_projections_iteration(A_0_sparse, A_0_nz, \n",
    "                                      A_sparse_list, A_nz_list, \n",
    "                                      c, \n",
    "                                      x_primal_var, z_primal_var_list, \n",
    "                                      lambda_dual_var,\n",
    "                                      sigma_dual_var_list, \n",
    "                                      pinv_C_cache,\n",
    "                                      run_checks = False):\n",
    "    \n",
    "    projection_strong_duality(A_0_sparse, A_0_nz, \n",
    "                              A_sparse_list, A_nz_list, \n",
    "                              c, \n",
    "                              x_primal_var, z_primal_var_list, \n",
    "                              lambda_dual_var,\n",
    "                              sigma_dual_var_list,\n",
    "                              pinv_C_cache)\n",
    "\n",
    "    if run_checks:\n",
    "        check = np.dot(c, x_primal_var) - (A_0_sparse @ lambda_dual_var).diagonal().sum()\n",
    "        if not np.allclose(check, 0):\n",
    "            raise Exception('Strong duality projection is inconsistent')\n",
    "\n",
    "    projection_dual_feasibility_equality_1(A_0_sparse, A_0_nz, \n",
    "                                              A_sparse_list, A_nz_list, \n",
    "                                              c, \n",
    "                                              x_primal_var, z_primal_var_list, \n",
    "                                              lambda_dual_var,\n",
    "                                              sigma_dual_var_list,\n",
    "                                              pinv_C_cache)\n",
    "\n",
    "    if run_checks:\n",
    "        for i in range(len(A_sparse_list)):\n",
    "            check = c[i] + (lambda_dual_var @ A_sparse_list[i]).diagonal().sum()\n",
    "            if not np.allclose(check, 0):\n",
    "                raise Exception('Dual feasibility equality 1 projection is inconsistent')\n",
    "        \n",
    "    for _ in range(1):\n",
    "        projection_dual_feasibility_equality_2(A_0_sparse, A_0_nz, \n",
    "                                              A_sparse_list, A_nz_list, \n",
    "                                              c, \n",
    "                                              x_primal_var, z_primal_var_list, \n",
    "                                              lambda_dual_var,\n",
    "                                              sigma_dual_var_list,\n",
    "                                              pinv_C_cache)\n",
    "    \n",
    "    \n",
    "    projection_primal_feasibility_equality(A_0_sparse, A_0_nz, \n",
    "                                          A_sparse_list, A_nz_list, \n",
    "                                          c, \n",
    "                                          x_primal_var, z_primal_var_list, \n",
    "                                          lambda_dual_var,\n",
    "                                          sigma_dual_var_list,\n",
    "                                          pinv_C_cache)\n",
    "    \n",
    "    if run_checks:\n",
    "        Lx = A_0_sparse\n",
    "        for i in range(len(A_sparse_list)):\n",
    "            Lx += A_sparse_list[i] * x_primal_var[i]\n",
    "\n",
    "        Z = np.zeros((n, n))\n",
    "        for block_idx in range(num_blocks):\n",
    "            diag_idx = block_idx*(b-1)\n",
    "            Z[diag_idx:diag_idx + b, diag_idx:diag_idx + b] += z_primal_var_list[block_idx]\n",
    "\n",
    "        check = Lx - Z\n",
    "        if not np.allclose(check, 0):\n",
    "            print(check)\n",
    "            raise Exception('Primal feasibility equality projection is inconsistent')\n",
    "\n",
    "        \n",
    "    for i in range(len(sigma_dual_var_list)):\n",
    "        project_psd_cone(sigma_dual_var_list[i])\n",
    "        project_psd_cone(z_primal_var_list[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_A = 1\n",
    "num_blocks = 10\n",
    "b = 3\n",
    "n = b + (num_blocks - 1) * (b - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project onto L(x) = \\sum E_i Z_i E_i'\n",
    "# generate indices of the nonzero entires for block sparsity pattern\n",
    "matrix_to_vector= {} # Map (i, j) to k\n",
    "vector_to_matrix_set = set() \n",
    "for block_index in range(num_blocks):\n",
    "    top_left = ((b - 1) * block_index, (b - 1) * block_index)\n",
    "    for (di, dj) in itertools.product(range(b), range(b)):\n",
    "        vector_to_matrix_set.add((top_left[0] + di, top_left[1] + dj))\n",
    "vector_to_matrix = list(vector_to_matrix_set)\n",
    "sparsity_pattern_rows = np.array([op[0] for op in vector_to_matrix])\n",
    "sparsity_pattern_cols = np.array([op[1] for op in vector_to_matrix])\n",
    "matrix_to_vector = {p:i for i, p in enumerate(vector_to_matrix)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_0_sparse = form_laplacian(n)\n",
    "A_0_nz = A_0_sparse.nonzero()\n",
    "A_0_sparse_vectorized = A_0_sparse[A_0_nz]\n",
    "\n",
    "A_sparse_list = [-np.eye(n)]\n",
    "A_nz_list = [A_sparse_list[i].nonzero() for i in range(len(A_sparse_list))]\n",
    "A_sparse_vectorized_list = [A_sparse_list[i][A_nz_list[i]] for i in range(len(A_sparse_list))]\n",
    "\n",
    "c = -np.ones((1,1))\n",
    "# x_primal_var = np.zeros(1)\n",
    "x_primal_var = np.zeros(1)\n",
    "z_primal_var_list = [np.zeros((b,b)) for _ in range(num_blocks)]\n",
    "lambda_dual_var = scipy.sparse.csr_matrix((n,n))\n",
    "sigma_dual_var_list = [np.zeros((b,b)) for _ in range(num_blocks)]\n",
    "pinv_C_cache = {}\n",
    "params = [\n",
    "    A_0_sparse, A_0_nz, \n",
    "    A_sparse_list, A_nz_list, \n",
    "    c, \n",
    "    x_primal_var, z_primal_var_list, \n",
    "    lambda_dual_var,\n",
    "    sigma_dual_var_list,\n",
    "    pinv_C_cache\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py:742: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00584627]\n",
      "[0.00616038]\n",
      "[0.00630331]\n",
      "[0.00638706]\n",
      "[0.00646565]\n",
      "[0.00653995]\n",
      "[0.00661069]\n",
      "[0.00667845]\n",
      "[0.00674365]\n",
      "[0.00680665]\n",
      "[0.00686769]\n",
      "[0.00692699]\n",
      "[0.00698472]\n",
      "[0.00704102]\n",
      "[0.00709602]\n",
      "[0.00714982]\n",
      "[0.0072025]\n",
      "[0.00725415]\n",
      "[0.00730483]\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(2000):\n",
    "    if iteration % 100 == 0:\n",
    "        print(x_primal_var)\n",
    "    alternating_projections_iteration(*params, run_checks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.020357116238134833"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.eigvalsh(A_0_sparse.todense()).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
